\begin{enumerate}
  \item \textbf{Goal:}


  \item \textbf{Two Types of Sequential Data:} We distinguish two kinds of sequential data:
  \begin{enumerate}
    \item \textit{Sationary Sequential Data:} It is useful to distinguish between stationary and nonstationary sequential distributions.
In the stationary case, the data evolves in time, but the distribution from
which it is generated remains the same. For the more complex nonstationary situation,
the generative distribution

  \end{enumerate}
\end{enumerate}

\item Relaxing i.i.d Assumption: Using the product rule, we write the joint probability density function of $X_1, X_2, \cdots, X_n$ as
\begin{align}
  f \parens{x_1, x_2, \cdots, x_n} = f \parens{x_1} \prod_{i=2}^n f \parens{x_i \,\vert\, x_1, x_2, \cdots, x_{i-1}}.
\end{align}
We assume each of the conditional distribution is independent of all previous observations except the most recent one, we obtain the \emph{first-order Markov chain}. That is, the joint probability density function can be written as
\begin{align}
  f \parens{x_1, x_2, \cdots, x_n} = f \parens{x_1} \prod_{i=2}^n f \parens{x_i \,\vert\, x_{i-1}}.
\end{align}

\textit{Remark.} The decomposition of the probability density function above means
\begin{align}
f \parens{x_n \,\vert\, x_1, x_2, \cdots, x_{n-1}} = f \parens{x_n \,\vert\, x_{n-1}}.
\end{align}
Therefore, conditional on x_{n-1}, x_n is independent of all past observations x_1, x_2, \cdots, x_{n-1}.

\item \textbf{Extensions:} The first-order Markov chain is general than the i.i.d assumption but may still be too restrictive. We can further relax in different manners:

We can obtain the second-order Markov model and let x_i depend only on the past two observations. In other words, we can decompose the joint probability densty function as
f \parens{x_1, x_2, \cdots, x_n} = f \parens{x_1} f \parens{x_2} \prod_{i=3}^n f \parens{x_i \,\vert\, x_{i-1}, x_{i-2}}.

Then, the conditional distribution of x_n, given x_{n-1} and x_{n-2}, is independent of all observations x_1, x_2, \cdots, x_{n-3}.
Each observation is influenced only by two previous observations.

Similarly, we can consider extensions to an $m$-th order Markov chain where the conditional distribution for a particular variable depends on the previous $m$ variables.

Drawback:



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\item Interpretations of HHM:


\item The latext variables are the discrete variables $Z_n$ describing which component of the mixture is responsible for generating the corresponding observations $X_n$.
We also allow the probability distribution of $Z_n$ to depend on the state of the previous latent variable $Z_{n-1}$ through a conditional distributon $p \parens{Z_n \,\vert\, Z_{n-1}}$


Probability distribution of the conditional variable

Since the latent variables are $K$ dimensional binary variables, this conditional distribution
corresponds to a table of numbers, denoted by $\bA$. The elements of $\bA$ are known as transition
probabilities and are given by
A_{j,k} := \Pr (z_{n} = k \,\vert\, Z_{nâˆ’1} = j), \qquad \text{ for all } j, k = 1, 2, \cdots, K,
and since they are probabilities, we must have
A_{j,k} \in \bracks{0, 1} for all j, k = 1, 2, \cdots, K,
and
\sum_{k=1}^K A_{j,k} = 1.
Hence, the matrix $\bA$ has $K \parens{K-1}$ independent parameters.

The initial latent node $Z_1$ is special, since it does not have a parent node. We assume $Z_1$ has a
marginal distribution f_{Z_1} represented by a vector of probabilities $\bpi$ with elements
\pi_k = \Pr \parens{Z_1 = k}, \qquad \text{ for all } k = 1, 2, \cdots, K.

The specification of the probabilistic model is completed by defining the conditional distributions of the observed variables
f \parens{x_i \,\vert\, Z_i, \bphi}, for all i = 1, 2, \cdots, n
called the \emph{emission probabilities}, where $\bphi$ is a set of parameters governing the distribution.

Since we assume $Z_i$'s are discrete random variables that can take on $K$ different values, $\bphi$ contains








================================================================================

L \parens{\btheta} := \Pr \parens{X_1 = x_1, X_2 = x_2, \cdots, X_n = x_n} = \sum_{z_1 = 1}^K \sum_{z_2 = 1}^K \cdots \sum_{z_n = 1}^K \Pr \parens{Z_1 = z_1, X_1 = x_1, \cdots, Z_n = z_n, X_n = x_n}

Difficulties of Maximizing $L$ Directly:
1. We cannot perform the summations explicitly since there are $n$ variables to be summed over, and each has $K$ states, resulting in a total of $K^n$ terms; 
1. There is dependence among z_n's, and we cannot treat each of the summations over z_i's
